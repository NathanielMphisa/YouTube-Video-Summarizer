{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6362e7-9a47-4707-b143-c8ca373f2226",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44b3420a-7330-41c6-af48-49fc7ca429d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from sumy.parsers.plaintext import PlaintextParser      \n",
    "from sumy.nlp.tokenizers import Tokenizer              \n",
    "from sumy.summarizers.lsa import LsaSummarizer  \n",
    "import nltk  \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c88a21-54ec-4293-9555-4b72d439a679",
   "metadata": {},
   "source": [
    "## Task 1: Design and Implementation\r",
    "Input (YouTube URL) → [Regex: Extract Video ID] → [YouTube Transcript API: Fetch Transcript] → [OpenAI API: Generate Summary] → Output (Summary) LSA-Based Summary  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c849efd-244c-4bc3-80d3-da7468e2b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract Video ID from YouTube URL\n",
    "def extract_video_id(url):\n",
    "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c834d3f-a4e5-41ee-9ebe-a8e981a17f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fetch Transcript from YouTube\n",
    "def fetch_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        text = ' '.join([entry['text'] for entry in transcript])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Could not fetch transcript: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ff8a14e-176f-428b-b3cc-444cc6490a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Summarize using Sumy LSA \n",
    "# Instead of the Open API, we used Sumy as OPEN AI requires a premium account\n",
    "\n",
    "def summarize_text_sumy(text, sentence_count=5):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    return '\\n'.join(str(sentence) for sentence in summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "792ca2c4-546b-4dce-a640-63b6091ae3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Full Process Function\n",
    "def extract_transcript(url):\n",
    "    video_id = extract_video_id(url)\n",
    "    if not video_id:\n",
    "        return \"[Error] Invalid YouTube URL format.\"\n",
    "\n",
    "    print(f\"Extracted Video ID: {video_id}\")\n",
    "\n",
    "    transcript = fetch_transcript(video_id)\n",
    "    if not transcript:\n",
    "        return \"[Error] No transcript available.\"\n",
    "        \n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d0d2540-1b84-4491-b4c3-80f46e2394db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to be used to generate Summary using OPEN AI\n",
    "def generate_summary(transcript, prompt_template):\n",
    "    client = OpenAI(api_key=\"XXXXXXXXXXX\")\n",
    "    prompt = prompt_template.format(transcript=transcript)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a concise summarizer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa0d174e-5a4d-4bbe-b7d7-732ac3505e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video URL:   https://www.youtube.com/watch?v=x7X9w_GIm1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Video ID: x7X9w_GIm1s\n",
      "\n",
      "--- Transcript Summary ---\n",
      "\n",
      "python a highlevel interpreted programming language famous for its zen-like code it's arguably the most popular language in the world because it's easy to learn yet practical for serious projects in fact you're watching this YouTube video in a python web application right now it was created by Guido van rossom and released in 1991 who named it after Monty Python's Flying Circus which is why you'll sometimes find spaming eggs instead of Foo and bar and code samples it's commonly used to build serers side applications like web apps with the framework and is the language of choice for Big Data analysis and machine learning many students choose python to start learning decode because of its emphasis on readability as outlined by the Zen of python beautiful is better than ugly while explicit is better than implicit python is very simple but avoids the temptation to sprinkle in Magic that causes ambiguity its code is often organized into notebooks where individual cells can be executed then documented in the same place we're currently at version three of the language and you can get started by creating a file that ends in py or iynb to create an interactive notebook create a variable by setting a name equal to a value it's strongly typed which means values won't change in unexpected ways but Dynamic so type annotations are not required the syntax is highly efficient allowing you to declare multiple variables on a single line and Define tupal lists and dictionaries with a literal syntax semicolons are not required and if you use them and experience pythonista will say that your code is not pythonic instead of semicolons python uses indentation to terminate or determine the scope of a line of code Define a function with the def keyword then indent the next line usually by four spaces to define the function body we might then add a for Loop to it and indent that by another four spaces this eliminates the need for curly braces and semicolons found in many other languages python is a multiparadigm language we can apply functional programming patterns with things like Anonymous functions using Lambda it also uses objects as an abstraction for data allowing you to implement objectoriented patterns with things like classes and inheritance it also has a huge ecosystem of thirdparty libraries such as deep learning Frameworks like tensorflow and rappers for many high performance low-level packages like open computer vision which are most often installed with the PIP package manager this has been the Python programming language in 100 seconds hit the like button if you want to see more short videos like this thanks for watching and I will see you in the next one\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    youtube_url = input(\"Enter the YouTube video URL: \")\n",
    "    result_Full_Transcript = extract_transcript(youtube_url)\n",
    "    summary = summarize_text_sumy(result_Full_Transcript)\n",
    "\n",
    "    print(\"\\n--- Transcript Summary ---\\n\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67dc70da-5b14-4ad2-a861-3617f1978b7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Testing Open AI\u001b[39;00m\n\u001b[0;32m      2\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the following transcript in 3-5 sentences, capturing the main points: \u001b[39m\u001b[38;5;132;01m{transcript}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m summary \u001b[38;5;241m=\u001b[39m generate_summary(result_Full_Transcript, prompt_template)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[1;34m(transcript, prompt_template)\u001b[0m\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-jOJrlDb2xHQBwILQTsYBpGR72rzTYS7pjJhwy7jK3GojNQYwRWic2ojl9khL_w6gCw2ZRiChStT3BlbkFJe4z8loN4LPy-2bpSrW1IlSv1IWjwuACGI7QNeNvs7nyyY9LUkKG46Ff_gn57gX9l_MJz79g-8A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(transcript\u001b[38;5;241m=\u001b[39mtranscript)\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      8\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a concise summarizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      9\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[0;32m     10\u001b[0m     ],\n\u001b[0;32m     11\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Testing Open AI\n",
    "prompt_template = \"Summarize the following transcript in 3-5 sentences, capturing the main points: {transcript}\"\n",
    "summary = generate_summary(result_Full_Transcript, prompt_template)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1819a-c981-4248-9401-942b817a4a77",
   "metadata": {},
   "source": [
    "#### Finding: Using Open AI requires a premium account hence resorted to using Sumy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b01356-1671-46c9-a8c2-a7c2014bdffb",
   "metadata": {},
   "source": [
    "## Task 2 Challenges and Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c1b28-baed-4688-b90c-303e55ad1034",
   "metadata": {},
   "source": [
    "### Challenges and Solutions\r\n",
    "\r\n",
    "#### Potential Challenges\r\n",
    "\r\n",
    "| Challenge               | Description |\r\n",
    "|--------------------------|-------------|\r\n",
    "| No transcript available  | Some videos have no captions or are auto-generated in unsupported languages. |\r\n",
    "| API rate limits          | OpenAI and YouTube Transcript APIs may restrict excessive requests. |\r\n",
    "| Long transcripts         | GPT models have input token limits (e.g., 4096 for GPT-3.5). |\r\n",
    "| Summary accuracy         | The model may misinterpret domain-specific content. |\r\n",
    "| Network errors           | Transcript fetching or API calls might fail intermittently. |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63742dc-ae07-46cf-b1ae-e4036b38fa25",
   "metadata": {},
   "source": [
    "#### Solutions and Workarounds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d47b0-25fd-4a7b-a67c-96d73a3d97d1",
   "metadata": {},
   "source": [
    "### Challenges and Solutions\r\n",
    "\r\n",
    "| Challenge            | Solution |\r\n",
    "|-----------------------|----------|\r\n",
    "| No transcript         | Display a friendly error message; suggest uploading a manual transcript. |\r\n",
    "| API limits            | Add exponential backoff and caching mechanisms; upgrade to higher API tiers if needed. |\r\n",
    "| Long transcripts      | Split transcript into chunks and summarize each, then summarize the summaries. |\r\n",
    "| Summary accuracy      | Use fine-tuned models or add technical glossary context in the prompt. |\r\n",
    "| Network issues        | Use try/except blocks and implement retries with logging. |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68158c8-954c-4b7a-9c40-5e49339604dc",
   "metadata": {},
   "source": [
    "#### Task 3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee27be-3d5d-4324-8c36-37f9092a2e0b",
   "metadata": {},
   "source": [
    "#### Evaluating Effectiveness: To evaluate the effectiveness of the summaries:\n",
    "\n",
    "User Feedback: Collect qualitative feedback from users (e.g., software engineers) on whether summaries capture key technical points and are concise.\n",
    "Comparison with Manual Summaries: Compare tool-generated summaries with human-written summaries of the same videos to assess completeness and accuracy.\n",
    "A/B Testing: Test different prompt variations (e.g., bullet-point vs. paragraph summaries) and measure user preference or task completion time (e.g., how quickly users grasp the video’s content).evant.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3598d-deed-4d12-8b29-c358714ad0d7",
   "metadata": {},
   "source": [
    "#### Metrics/Methods for Quality and Accuracy\n",
    "\n",
    "Metrics:\n",
    "\n",
    "ROUGE Score: Measure overlap between tool-generated summaries and human-written reference summaries (e.g., ROUGE-1 for word overlap, ROUGE-L for sequence similarity).\n",
    "\n",
    "Cosine Similarity: Compute semantic similarity between the summary and transcript embeddings (using models like BERT or SentenceTransformers).\n",
    "\n",
    "Conciseness Ratio: Ratio of summary length to transcript length (target: 5-10% of original length).\n",
    "\n",
    "Methods:\n",
    "Manual Review: Have domain experts (e.g., engineers) rate summaries on a scale (e.g., 1-5) for accuracy, relevance, and clarity.\n",
    "Task-Based Evaluation: Ask users to answer questions about the video’s content using only the summary, measuring correctness.well.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051bda2-1a2f-4ee0-9976-429650a54aa9",
   "metadata": {},
   "source": [
    "## Task 4 Extension: Proposed Features\r\n",
    "\r\n",
    "| Feature                  | Benefit |\r\n",
    "|---------------------------|---------|\r\n",
    "| Multi-language Support    | Use translation APIs or multilingual models for non-English transcripts. |\r\n",
    "| Browser Extension         | Users can summarize any video directly while browsing YouTube. |\r\n",
    "| Summarization Modes       | Allow user to choose between bullet points, paragraph, or TL;DR format. |\r\n",
    "| Visual Summaries          | Generate mind maps or key-point graphics using tools like Graphviz. |\r\n",
    "| Bookmarking and Saving    | Save past summaries and allow search/filter functionality. |\r\n",
    "| Voice Summary Generation  | Use TTS (text-to-speech) APIs to produce audio summries. |\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdf6cf-4065-4e28-aeff-9ffab3e4c8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
